# devForge
ğŸ¬ Text-to-Animated-Video Generator

Convert natural language into fully animated Manim videos using LLM-driven JSON planning & procedural animation.

This project transforms any text descriptionâ€”such as:

â€œShow a ball launched in a parabolic trajectory.â€

into a complete Manim animation, rendered as an MP4 video.
It uses a multi-stage pipeline combining LLM planning, JSON validation, motion logic, and video rendering.

ğŸš€ Features
1. Text â†’ Structured JSON Scene Plan

Your input text is enhanced by an LLM (Gemini API) to generate a structured JSON describing:

Scene titles

Objects (Dot, Text, Axes, Circle, Square, Paths, Parametric curves, etc.)

Actions (FadeIn, Create, MoveAlongPath, FadeOut, Animate motion)

Scene hints (e.g., â€œprojectile motionâ€, â€œparabolic trajectoryâ€)

Optional physics parameters

2. JSON â†’ Manim Python Code

The JSON plan is validated and transformed into executable Manim CE code, producing:

Multi-object animations

Parametric motion (projectile arcs, curves, custom paths)

Camera-ready Manim scenes

Automatic class naming

Clean & safe Python code generation

3. Automatic Video Rendering

The generated Manim code is executed automatically to produce:

project_root/media/videos/<scene>/<resolution>/<video>.mp4


Your pipeline even locates the final video file automatically.

4. Fallback Mode

If no LLM API key is available, or the enhancement fails, the system uses a deterministic fallback plan so the pipeline still works.


ğŸ§  Pipeline Overview
User Text
   â†“
Gemini Enhancer (Text â†’ JSON)     â† requires your API key
   â†“
Plan Validator (safety checks)
   â†“
Training Pipeline (JSON â†’ Manim code)
   â†“
Render Pipeline (Manim â†’ MP4)
   â†“
Final Animated Video


ğŸ”‘ Environment Setup (IMPORTANT)

Create a file named .env in the project root:

GEMINI_API_KEY=YOUR_OWN_KEY_HERE
GEMINI_API_ENDPOINT=YOUR_OWN_ENDPOINT_HERE

â— You MUST attach your own API key & endpoint

The enhancer uses Gemini LLM to convert text â†’ JSON.
Without your key, the system falls back to deterministic mode.

â–¶ï¸ Running the Generator

Use:

python render_pipeline.py "a ball launched in a parabolic trajectory"


The script will:

Generate a JSON scene plan

Produce Manim CE code

Render MP4 video

Print the final video path

Example output:

Rendered video: C:\Users\You\Project\media\videos\Projectile\1080p60\Projectile.mp4



ğŸ“ Project Structure
viva/
â”‚
â”œâ”€â”€ render_pipeline.py        # Main entrypoint (text â†’ video)
â”œâ”€â”€ genai_enhancer.py         # LLM-based JSON generator
â”œâ”€â”€ training_pipeline.py      # JSON â†’ Manim code
â”œâ”€â”€ plan_validator.py         # Schema validation + autofill
â”œâ”€â”€ train_slm.py              # Fine-tuning script for custom SLM
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ plans/                # Generated JSON plans
â”‚   â”œâ”€â”€ manim_code/           # Generated Manim Python files
â”‚   â””â”€â”€ videos/               # Optional saved videos
â”‚
â”œâ”€â”€ training/
â”‚   â””â”€â”€ generated_data/       # Dataset for training SLM
â”‚
â”œâ”€â”€ media/                    # Manim auto-generated output
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore



â¤ï¸ Contributing

Fork

Create a new branch

Submit a PR

Wait for review

Pull requests are welcome!


